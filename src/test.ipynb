{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00053fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensordict import TensorDict\n",
    "from dataset.OnlineDataset import OnlineDataset\n",
    "from dataset.OfflineDataset import OfflineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b654bb45",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OnlineDataset.__init__() got an unexpected keyword argument 'customer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mOnlineDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/1_processed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m              \u001b[49m\u001b[43msliding_window_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m336\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m              \u001b[49m\u001b[43msliding_window_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m336\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m              \u001b[49m\u001b[43mforecast_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m              \u001b[49m\u001b[43mcustomer\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m              \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_dt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: OnlineDataset.__init__() got an unexpected keyword argument 'customer'"
     ]
    }
   ],
   "source": [
    "ds = OnlineDataset(raw_data_path='../data/1_processed',\n",
    "              sliding_window_offset=336,\n",
    "              sliding_window_size=336,\n",
    "              forecast_size=32,\n",
    "              customer=13,\n",
    "              mode='train_dt',\n",
    "              device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e0169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57de528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = OfflineDataset(generated_data_path='../data/2_generated',\n",
    "\t\t\t  sliding_window_offset=1344,\n",
    "\t\t\t  sliding_window_size=1344,\n",
    "\t\t\t  building_id=13,\n",
    "\t\t\t  device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b712e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1344])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79cac6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e89cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_ids = []\n",
    "for filename in os.listdir('../data/2_generated/'):\n",
    "\tif filename.endswith(\".pt\") and filename[:-3].isdigit():\n",
    "\t\tbuilding_ids.append(int(filename[:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e66128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_offline_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f506bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_offline_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4db1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389f6ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5],\n",
       "        [5, 6],\n",
       "        [6, 7],\n",
       "        [7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.unfold(dimension=0, size=2, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301848da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897889b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f0fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a4375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5a654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e2f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83296891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509f742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf3e977",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/2_generated/1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m torch.sum(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/2_generated/1.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcost\u001b[39m\u001b[33m'\u001b[39m], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dtkd/lib/python3.13/site-packages/torch/serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dtkd/lib/python3.13/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dtkd/lib/python3.13/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/2_generated/1.pt'"
     ]
    }
   ],
   "source": [
    "torch.sum(torch.load('../data/2_generated/1.pt', weights_only=False)['next', 'cost'], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([20.0]).reshape(1, 1)[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20835072",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = torch.load('../data/2_generated/13.pt',weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.OfflineDataset import OfflineDataset\n",
    "OfflineDataset(cfg=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba23df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_to_unfold_td(td):\n",
    "    new_td = TensorDict({}, batch_size=(51,336))\n",
    "    for key, tensor in td.items():\n",
    "        if key=='next':\n",
    "            new_td[key] = td_to_unfold_td(tensor)\n",
    "        elif key=='params':\n",
    "            new_td[key] = td_to_unfold_td(tensor.unsqueeze(-1))\n",
    "        else:\n",
    "            new_td[key] = tensor.unfold(dimension=0,size=336,step=336).permute(0,2,1)\n",
    "    return new_td\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c28e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        cost: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_init: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                cost: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                is_init: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([51, 336, 65]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                params: TensorDict(\n",
       "                    fields={\n",
       "                        battery_capacity: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_power: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_steps: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "                    batch_size=torch.Size([51, 336]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                price: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                price_forecast: Tensor(shape=torch.Size([51, 336, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                prosumption: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                prosumption_forecast: Tensor(shape=torch.Size([51, 336, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                soe: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                step: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([51, 336]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([51, 336, 65]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                battery_capacity: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_power: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_steps: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "            batch_size=torch.Size([51, 336]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        price: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        price_forecast: Tensor(shape=torch.Size([51, 336, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption_forecast: Tensor(shape=torch.Size([51, 336, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        soe: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        step: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([51, 336, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([51, 336]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = td_to_unfold_td(td)\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000],\n",
       "         [ 0.4034],\n",
       "         [ 0.3103],\n",
       "         ...,\n",
       "         [-0.0209],\n",
       "         [-0.0091],\n",
       "         [ 0.3398]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.4556],\n",
       "         [ 0.3488],\n",
       "         ...,\n",
       "         [-0.0224],\n",
       "         [ 0.0051],\n",
       "         [ 0.1750]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.2702],\n",
       "         [ 0.2701],\n",
       "         ...,\n",
       "         [ 0.2037],\n",
       "         [ 0.3049],\n",
       "         [ 0.5744]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.5681],\n",
       "         [ 0.4791],\n",
       "         ...,\n",
       "         [ 0.0719],\n",
       "         [-0.0055],\n",
       "         [ 0.2846]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.4365],\n",
       "         [ 0.4062],\n",
       "         ...,\n",
       "         [ 0.4241],\n",
       "         [ 0.3023],\n",
       "         [ 0.5073]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.6102],\n",
       "         [ 0.4493],\n",
       "         ...,\n",
       "         [ 0.1859],\n",
       "         [ 0.0749],\n",
       "         [ 0.3455]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c765b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 336, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(torch.cumsum(td['cost'],dim=1),dims=[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaadeb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([336])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def td_to_unfold_td(td):\n",
    "    new_td = TensorDict({}, batch_size=(51,336))\n",
    "    for key, tensor in td.items():\n",
    "        if key=='next':\n",
    "            new_td[key] = td_to_unfold_td(tensor)\n",
    "        elif key=='params':\n",
    "            new_td[key] = td_to_unfold_td(tensor.unsqueeze(-1))\n",
    "        else:\n",
    "            new_td[key] = tensor.unfold(dimension=0,size=336,step=336).permute(0,2,1)\n",
    "    return new_td\n",
    "td_to_unfold_td(td)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc303258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,2,3,4,5,6,7])[torch.tensor([1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.714],\n",
       "       [ 1.374],\n",
       "       [ 1.238],\n",
       "       [ 0.094],\n",
       "       [ 0.92 ],\n",
       "       [ 0.468],\n",
       "       [ 0.487],\n",
       "       [ 0.088],\n",
       "       [ 0.833],\n",
       "       [ 0.553],\n",
       "       [ 0.529],\n",
       "       [ 0.043],\n",
       "       [ 0.086],\n",
       "       [ 0.045],\n",
       "       [ 0.088],\n",
       "       [ 0.094],\n",
       "       [ 0.1  ],\n",
       "       [ 0.004],\n",
       "       [ 0.032],\n",
       "       [ 1.057],\n",
       "       [ 1.179],\n",
       "       [-0.234],\n",
       "       [-0.646],\n",
       "       [-0.722],\n",
       "       [-0.913],\n",
       "       [-0.786],\n",
       "       [-0.916],\n",
       "       [-1.012],\n",
       "       [-1.034],\n",
       "       [-0.793],\n",
       "       [-0.62 ],\n",
       "       [-0.256],\n",
       "       [ 0.035],\n",
       "       [ 0.042],\n",
       "       [ 0.122],\n",
       "       [ 0.231],\n",
       "       [ 0.379],\n",
       "       [ 0.321],\n",
       "       [ 0.262],\n",
       "       [ 0.234],\n",
       "       [ 0.306],\n",
       "       [ 0.183],\n",
       "       [ 0.24 ],\n",
       "       [ 0.17 ],\n",
       "       [ 0.506],\n",
       "       [ 0.224],\n",
       "       [ 0.088],\n",
       "       [ 1.159]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['prosumption'][0:48].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6be76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6698443 ],\n",
       "       [1.2494212 ],\n",
       "       [0.72873247],\n",
       "       [0.4567207 ],\n",
       "       [0.29952443],\n",
       "       [0.16238034],\n",
       "       [0.        ],\n",
       "       [0.21299982],\n",
       "       [0.26120257],\n",
       "       [0.34071386]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['soe'][330:340].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dec68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0304],\n",
       "        [0.2672],\n",
       "        [0.4001],\n",
       "        [0.6886],\n",
       "        [1.1291],\n",
       "        [0.8816],\n",
       "        [1.4434],\n",
       "        [1.6692],\n",
       "        [1.3714],\n",
       "        [1.0854],\n",
       "        [1.1297],\n",
       "        [0.8424],\n",
       "        [0.6250],\n",
       "        [0.4896],\n",
       "        [0.4889],\n",
       "        [0.4522],\n",
       "        [0.6708],\n",
       "        [0.9569],\n",
       "        [1.2640],\n",
       "        [1.5770],\n",
       "        [1.8141],\n",
       "        [1.7581],\n",
       "        [1.9911],\n",
       "        [2.5032],\n",
       "        [3.2007],\n",
       "        [3.8028],\n",
       "        [4.4131],\n",
       "        [4.9345],\n",
       "        [5.5240],\n",
       "        [6.1548],\n",
       "        [6.3679],\n",
       "        [6.1504],\n",
       "        [5.8415],\n",
       "        [5.4406],\n",
       "        [5.0861],\n",
       "        [4.6516],\n",
       "        [4.2049],\n",
       "        [3.6788],\n",
       "        [3.1315],\n",
       "        [2.6518],\n",
       "        [2.2922],\n",
       "        [2.0066],\n",
       "        [1.6155],\n",
       "        [1.2880],\n",
       "        [1.3060],\n",
       "        [1.2421],\n",
       "        [0.8532]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['soe'][48:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae988d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d2114",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorDict' object has no attribute 'unfold'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtd\u001b[49m\u001b[43m.\u001b[49m\u001b[43munfold\u001b[49m(dimension=\u001b[32m0\u001b[39m,size=\u001b[32m48\u001b[39m+\u001b[32m32\u001b[39m,step=\u001b[32m48\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'TensorDict' object has no attribute 'unfold'"
     ]
    }
   ],
   "source": [
    "td.unfold(dimension=0,size=48+32,step=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3,dtype=torch.int32)\n",
    "torch.cat([torch.tensor([]),x]).to(dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OfflineTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c23dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = trainer.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823f3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = torch.empty(2, 48,65)\n",
    "\n",
    "states[0] = torch.cat([torch.zeros((48 - 2, 65)),torch.ones(2,65)],dim=0)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b48e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.2759,  0.2759,  0.2759,  ..., -1.0120, -0.9610, 10.0000],\n",
       "          [ 0.2759,  0.2759,  0.2203,  ..., -0.9610, -0.5500, 10.0000]]]),\n",
       " tensor([[[0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.0000],\n",
       "          [0.3614],\n",
       "          [0.4105]]], grad_fn=<CopySlices>),\n",
       " tensor([[0.4541],\n",
       "         [0.0000]]),\n",
       " tensor([[    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0., 17470., 17471.]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.empty(2, 48,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df5886",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't assign a tuple to a torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m=obs\n\u001b[32m      2\u001b[39m states\n",
      "\u001b[31mTypeError\u001b[39m: can't assign a tuple to a torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "states[0]=obs\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.OfflineDataset import OfflineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af3e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OfflineDataset.__init__() got an unexpected keyword argument 'generated_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mOfflineDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/2_generated/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustomer\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: OfflineDataset.__init__() got an unexpected keyword argument 'generated_data_path'"
     ]
    }
   ],
   "source": [
    "ds = OfflineDataset(None, customer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6874ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        cost: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_init: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                cost: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                is_init: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([2, 65]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                params: TensorDict(\n",
       "                    fields={\n",
       "                        battery_capacity: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        dataset: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                        init_soe: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_power: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_steps: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "                    batch_size=torch.Size([2]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                price: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                price_forecast: Tensor(shape=torch.Size([2, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                prosumption: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                prosumption_forecast: Tensor(shape=torch.Size([2, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rtg: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                soe: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                step: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([2]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([2, 65]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                battery_capacity: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dataset: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                init_soe: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_power: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_steps: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "            batch_size=torch.Size([2]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        price: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        price_forecast: Tensor(shape=torch.Size([2, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption_forecast: Tensor(shape=torch.Size([2, 31]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        rtg: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        soe: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        step: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[17470:17490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44721ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc14f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756da8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216bd968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.OfflineDataset import OfflineDataset\n",
    "import torch\n",
    "from tensordict import TensorDict\n",
    "from torch.utils.data import DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244adbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9c6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f93b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.OnlineDataset import EnergyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EnergyDataset(raw_data_path='../data/1_processed', forecast_size=12, customer=1,mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa51771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea27fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5530)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['load'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971f4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3540, 1.5840, 1.3780, 1.3290, 0.2890, 0.7010, 1.0310, 0.1200, 0.0800,\n",
       "        0.5780, 1.0340, 0.0840, 0.1160, 0.0800, 0.7970, 1.0600, 0.2690, 0.3090,\n",
       "        0.1640, 0.6310, 1.4860, 1.3660, 1.4660, 1.1910, 1.2260, 1.6280, 0.6170,\n",
       "        1.1650, 1.1540, 1.1040, 0.3750, 0.1180, 0.2350, 0.4450, 1.1830, 1.1900,\n",
       "        0.5550, 0.4050, 0.2620, 1.1000, 1.0120, 0.8170, 0.5260, 0.3350, 0.4020,\n",
       "        0.1420, 0.1200, 1.1990, 1.9800, 2.6330, 2.0420, 1.8870, 0.7290, 1.6740,\n",
       "        1.2830, 0.1310, 0.2950, 1.0500, 0.1060, 0.3500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict({\n",
    "    'soe': torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = td.unfold(0,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 3), dtype=torch.int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDict({'soe':x},batch_size=4)[0:0]['soe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59522808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0590)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict({\n",
    "    'soe': torch.randint(0,10,(17520,1), dtype=torch.float32),\n",
    "    'action': torch.randint(-1,1,(17520,1), dtype=torch.float32),\n",
    "    'prosumption': torch.randint(-2,2,(17520,1), dtype=torch.float32),\n",
    "    'prosumption_forecast': torch.randint(-2,2,(17520,5), dtype=torch.float32),\n",
    "    'observation': torch.randint(-2,2,(17520,10), dtype=torch.float32),\n",
    "    \n",
    "}, batch_size=torch.Size([17520,]),\n",
    "device='cpu'\n",
    ")\n",
    "torch.save(td, '../output/1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e934bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([17520, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([17520, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption: Tensor(shape=torch.Size([17520, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption_forecast: Tensor(shape=torch.Size([17520, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        soe: Tensor(shape=torch.Size([17520, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([17520]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67473f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = OfflineDataset('../output',1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        prosumption_forecast: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        soe: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db657d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = iter(DataLoader(dataset=td, batch_size=1, shuffle=True, collate_fn=lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49352ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = iter(DataLoader(dataset=dataset, batch_size=1, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e056d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bfffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffData():\n",
    "    def __init__(self, generated_data_path, batch_size, ep_len):\n",
    "        self._td = torch.load(generated_data_path, weights_only=False)\n",
    "        self._batch_size = batch_size\n",
    "        self._ep_len = ep_len\n",
    "        self._num_traj = int(td.batch_size.numel() / ep_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_traj\n",
    "    \n",
    "    def sample(self):\n",
    "        inds = torch.randint(low=0, high=self._num_traj-1, size=(self._batch_size,))\n",
    "        \n",
    "        s, a, r, rtg, t = [],[],[],[],[]\n",
    "        for i in inds:\n",
    "            traj = self._td[i:i+self._ep_len]\n",
    "            s.append(traj['observation'].unsqueeze(0))\n",
    "            a.append(traj['action'].unsqueeze(0))\n",
    "            # r.append(traj['next','observation'].unsqueeze(-1))\n",
    "            t.append(np.arange(0,self._ep_len))\n",
    "        states = torch.cat(s, dim=0)\n",
    "        actions = torch.cat(a, dim=0)\n",
    "        # rewards = torch.cat(r, dim=0)\n",
    "        timesteps = torch.from_numpy(np.concatenate(t, axis=0))\n",
    "\n",
    "        return states, actions, timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402600c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.,  0.,  1.,  1.,  0., -2.,  1.,  0., -2.,  0.],\n",
       "          [ 1., -1.,  1.,  1., -2.,  0., -2.,  0.,  1.,  1.],\n",
       "          [ 0., -1.,  0.,  0., -1.,  0., -2., -1.,  1.,  1.],\n",
       "          [ 0., -2.,  0.,  0., -2., -1.,  1., -1., -2.,  1.],\n",
       "          [ 0., -2., -1., -2., -2., -1.,  1., -1., -1.,  1.],\n",
       "          [ 0., -2.,  0.,  0., -1., -2., -2.,  0., -1.,  0.],\n",
       "          [-2., -2.,  1.,  1., -2.,  1., -1., -2.,  1., -1.],\n",
       "          [-1., -1., -1., -1., -2.,  1.,  0.,  0.,  0.,  0.],\n",
       "          [-2., -2., -1.,  0., -1., -1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -2.,  0.,  0., -1., -1., -2.,  1.,  1., -1.],\n",
       "          [ 1.,  1., -2., -1.,  0.,  0., -2.,  0.,  1., -1.],\n",
       "          [-1., -2., -1.,  0., -2.,  1., -1., -1., -1., -1.],\n",
       "          [ 0., -1., -1., -1.,  0.,  0.,  1.,  0., -2., -1.],\n",
       "          [-1.,  1.,  1., -1.,  1.,  0.,  1.,  0., -1., -2.],\n",
       "          [-1., -2.,  1., -2.,  0.,  0., -1., -1.,  0., -1.],\n",
       "          [ 0., -1., -2., -1., -2.,  1., -2., -2.,  0., -1.],\n",
       "          [ 0., -2., -1., -2., -2., -2.,  1.,  0.,  0.,  1.],\n",
       "          [ 0.,  0.,  0.,  0.,  1., -2.,  1., -2., -2.,  1.],\n",
       "          [ 1., -2., -1., -2., -2., -1., -2., -2.,  0.,  0.],\n",
       "          [-2., -1.,  1., -2., -1.,  1., -1.,  1.,  0.,  0.],\n",
       "          [ 1., -1., -2.,  1.,  0.,  0.,  1., -2., -1.,  1.],\n",
       "          [-2.,  0.,  0., -1., -2., -2., -2., -2.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  0., -1.,  0., -1., -1.,  1.,  0.],\n",
       "          [ 0.,  1.,  0., -1., -2.,  0., -1.,  0.,  1.,  1.],\n",
       "          [ 0.,  1., -2., -1.,  1., -2.,  1.,  1., -2.,  0.],\n",
       "          [ 1.,  0., -2., -2., -2.,  0., -2., -1., -2.,  1.],\n",
       "          [-1., -1.,  1., -1., -1., -1., -2., -1.,  1.,  0.],\n",
       "          [ 1.,  1., -1.,  1.,  0., -1., -1.,  0., -1.,  1.],\n",
       "          [-1., -2., -1.,  1.,  1., -1., -1., -1.,  1., -1.],\n",
       "          [-2., -2., -1., -2.,  0., -1.,  0.,  0.,  1., -2.],\n",
       "          [-2., -1.,  0., -1., -2., -1.,  1., -2., -2., -2.],\n",
       "          [-1.,  1., -1.,  1.,  0.,  0., -2.,  1.,  1., -1.],\n",
       "          [ 0., -2., -2., -2.,  0.,  0.,  0., -1., -2., -2.],\n",
       "          [-1.,  0.,  1.,  0., -2., -1.,  1.,  1., -2.,  0.],\n",
       "          [ 1.,  1., -1.,  1.,  0., -2., -1., -1.,  1., -1.],\n",
       "          [-2.,  1.,  0., -2., -2.,  1.,  0.,  0.,  1.,  0.],\n",
       "          [ 0.,  1.,  1.,  0., -2.,  1., -2.,  0., -1.,  0.],\n",
       "          [ 1., -1., -1., -1.,  0.,  0.,  0., -2.,  0.,  0.],\n",
       "          [ 0.,  0.,  1., -2., -2., -2.,  0., -2.,  1., -2.],\n",
       "          [ 1.,  0.,  1.,  0., -1., -1.,  0., -2., -1., -1.],\n",
       "          [ 0.,  0.,  1., -1.,  1., -2.,  0., -2., -1., -2.],\n",
       "          [-1., -1.,  1.,  1., -1.,  0., -1., -1., -2.,  1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1.,  0., -2.,  1.,  0.],\n",
       "          [-1.,  0., -2., -2., -2., -2.,  1.,  0., -2., -1.],\n",
       "          [ 1., -1., -2.,  0.,  0., -1., -1.,  1., -1., -2.],\n",
       "          [-2.,  1.,  0., -2.,  1.,  0.,  0., -1., -1.,  0.],\n",
       "          [-1., -2., -1., -1.,  1., -1., -1., -2.,  0., -1.],\n",
       "          [ 0.,  1.,  0., -1.,  1.,  0.,  1., -2.,  0.,  0.]]]),\n",
       " tensor([[[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [-1.]]]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OffData('../output/1.pt', 1,48).sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtkd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
